{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "197bddfa-e4b8-4ccc-806a-f2bd9f6a5e26",
   "metadata": {},
   "source": [
    "### VECTOR Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b425ec9-08f4-4be7-947c-5dc267d5d106",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6b425ec9-08f4-4be7-947c-5dc267d5d106",
    "outputId": "3fb6d18a-e3fe-458d-a455-d1c2c907b8fc"
   },
   "outputs": [],
   "source": [
    "# FILE LOADER\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"/Users/rehan/openai/textbook_pdfs/chemistry10.pdf\"\n",
    "\n",
    "def file_loader(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load_and_split()\n",
    "    return pages\n",
    "\n",
    "pages = file_loader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70e8271-8157-465d-b94d-06ef290868e5",
   "metadata": {
    "id": "f70e8271-8157-465d-b94d-06ef290868e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "# LOAD FAISS DB / VECTOR DB\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "def create_embedding(pages):\n",
    "    vector_store = FAISS.from_documents(pages, OpenAIEmbeddings(model=\"text-embedding-3-large\"))\n",
    "    return vector_store\n",
    "\n",
    "def load_embedding(name):\n",
    "    vector_store = FAISS.load_local(name, OpenAIEmbeddings(model=\"text-embedding-3-large\"))\n",
    "    return vector_store\n",
    "\n",
    "def save_embedding(name, vector_store):\n",
    "    vector_store.save_local(name)\n",
    "\n",
    "vector_store = create_embedding(pages)\n",
    "save_embedding(\"chemistry10\", vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8536206b-a367-44f2-ad95-03c566320f2e",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d90eb0e-30b7-4430-997d-225b1dd42e8e",
   "metadata": {
    "id": "6d90eb0e-30b7-4430-997d-225b1dd42e8e",
    "outputId": "b3cf825c-7d31-4434-c30c-f8ad7135a508",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SIMILARITY SEARCH\n",
    "# FIND THE MOST MATCHING PAGE\n",
    "\n",
    "def search(question, vector_store, k=2):\n",
    "    docs = vector_store.similarity_search(question, k)\n",
    "    context = \"\"\n",
    "    for doc in docs:\n",
    "        context += doc.page_content\n",
    "        # print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:10000])\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8e712-ffd4-4c83-959d-bce20c58658d",
   "metadata": {},
   "source": [
    "### Template Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a1673d-71a4-46f0-9827-5c389bfe2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "{instruction} Please provide a brief response consisting of {number} distinct points.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd8de85-02c0-4636-9007-cb1c4e276f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTION\n",
    "instruction = \"\"\"As a student studying Class 10 History following the CBSE curriculum, I kindly request your assistance in answering a set of questions related to the Class 10 history exam. In order to ensure accuracy, please base your responses solely on the information presented in the context. It is crucial that you strictly adhere to the precise wording used in the context and refrain from incorporating any external knowledge into your answers.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435dcb3d-f4f1-45cb-884d-f16ee06209fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER QUESTION\n",
    "#question = \"Explain the meaning and notion of ‘Swaraj’ as perceived by the plantation workers. How did they respond to the call of ‘the Non – Cooperation movement’?\"\n",
    "\n",
    "#number = \"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aadb1b",
   "metadata": {},
   "source": [
    "### Token Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "423f0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "def num_tokens(message, model=\"gpt-3.5-turbo-0613\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(message))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d1ed3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_log(instruction, question, context, answer):\n",
    "    with open('logs.txt', 'a') as file:\n",
    "        file.write(f\"Instruction: {instruction}\\n\")\n",
    "        file.write(f\"Question: {question}\\n\")\n",
    "        file.write(f\"Context: {context}\\n\")\n",
    "        file.write(f\"Answer: {answer}\\n\")\n",
    "        file.write(\"--------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60c938b-e6f8-4be0-a45b-bf80c18c5199",
   "metadata": {},
   "source": [
    "### Run langchang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13f20cac-fe6f-493d-8fca-d0597db26d96",
   "metadata": {
    "id": "13f20cac-fe6f-493d-8fca-d0597db26d96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "what is swaraj\n",
      "Response:\n",
      "1. Swaraj was interpreted by tribal peasants and plantation workers in their own ways, based on their understanding of Mahatma Gandhi's message.\n",
      "2. For the tribal peasants, swaraj meant being able to graze their cattle, collect fuel wood and fruits from the forests, and retain their traditional rights.\n",
      "3. Alluri Sitaram Raju, a leader of the Gudem Hills rebellion, believed that swaraj could only be achieved through the use of force, not non-violence.\n",
      "4. For plantation workers in Assam, swaraj meant the right to move freely in and out of the confined space in which they were enclosed, and retaining a link with their villages.\n",
      "5. The visions of swaraj held by these movements were not defined by the Congress programme, but they emotionally related to an all-India agitation and identified with a movement that went beyond the limits of their immediate locality.\n",
      "Input tokens: 1008\n",
      "Output tokens: 186\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# vector_store = create_embedding(pages)\n",
    "# save_embedding(\"science10\", vector_store)\n",
    "vector_store = load_embedding(\"history10\")\n",
    "\n",
    "question = input(\"Question: \")\n",
    "number = str(input(\"Marks: \"))\n",
    "\n",
    "context_text = search(question, vector_store)\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt_template.format(instruction=instruction, number=number, context=context_text, question=question)\n",
    "# print(prompt)\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "response_text = model.predict(prompt)\n",
    "formatted_response = f\"Response:\\n{response_text}\"\n",
    "\n",
    "print(\"Question:\\n\" + question)\n",
    "print(formatted_response)\n",
    "\n",
    "print(\"Input tokens: \" + str(num_tokens(prompt)))\n",
    "print(\"Output tokens: \" + str(num_tokens(response_text)))\n",
    "\n",
    "update_log(instruction, question, context_text, response_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
